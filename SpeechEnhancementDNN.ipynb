{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/yongxuUSTC/sednn\n",
    "\n",
    "import os\n",
    "import soundfile\n",
    "import numpy as np\n",
    "import argparse\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import pickle\n",
    "import cPickle\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import prepare_data as data_preparation\n",
    "import config as configuration\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "        \n",
    "def read_audio_file(file_path, target_sample_rate=None):\n",
    "    (audio, sample_rate) = soundfile.read(file_path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_sample_rate is not None and sample_rate != target_sample_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "        sample_rate = target_sample_rate\n",
    "    return audio, sample_rate\n",
    "\n",
    "\n",
    "def write_audio_file(file_path, audio_data, sample_rate):\n",
    "    soundfile.write(file=file_path, data=audio_data, samplerate=sample_rate)\n",
    "\n",
    "def generate_mixture_csv(arguments):\n",
    "    workspace_directory = arguments.workspace_directory\n",
    "    speech_directory = arguments.speech_directory\n",
    "    noise_directory = arguments.noise_directory\n",
    "    data_type = arguments.data_type\n",
    "    amplification = arguments.amplification\n",
    "    sample_rate = configuration.sample_rate\n",
    "\n",
    "    speech_file_names = [file_name for file_name in os.listdir(speech_directory) if file_name.lower().endswith(\".wav\")]\n",
    "    noise_file_names = [file_name for file_name in os.listdir(noise_directory) if file_name.lower().endswith(\".wav\")]\n",
    "\n",
    "    random_state = np.random.RandomState(0)\n",
    "    output_csv_path = os.path.join(workspace_directory, \"mixture_csvs\", \"%s.csv\" % data_type)\n",
    "    data_preparation.create_folder(os.path.dirname(output_csv_path))\n",
    "\n",
    "    count = 0\n",
    "    csv_file = open(output_csv_path, 'w')\n",
    "    csv_file.write(\"%s\\t%s\\t%s\\t%s\\n\" % (\"speech_file\", \"noise_file\", \"noise_start\", \"noise_end\"))\n",
    "    for speech_file_name in speech_file_names:\n",
    "        # Read speech file.\n",
    "        speech_file_path = os.path.join(speech_directory, speech_file_name)\n",
    "        (speech_audio, _) = read_audio_file(speech_file_path)\n",
    "        speech_length = len(speech_audio)\n",
    "\n",
    "        # For training data, mix each speech with randomly selected #amplification noise files.\n",
    "        if data_type == 'training':\n",
    "            selected_noise_file_names = random_state.choice(noise_file_names, size=amplification, replace=False)\n",
    "        # For testing data, mix each speech with all noise files.\n",
    "        elif data_type == 'testing':\n",
    "            selected_noise_file_names = noise_file_names\n",
    "        else:\n",
    "            raise Exception(\"data_type must be training | testing!\")\n",
    "\n",
    "        # Mix one speech with different noise files multiple times.\n",
    "        for noise_file_name in selected_noise_file_names:\n",
    "            noise_file_path = os.path.join(noise_directory, noise_file_name)\n",
    "            (noise_audio, _) = read_audio_file(noise_file_path)\n",
    "\n",
    "            noise_length = len(noise_audio)\n",
    "\n",
    "            if noise_length <= speech_length:\n",
    "                noise_start = 0\n",
    "                noise_end = speech_length\n",
    "            # If noise is longer than speech, then randomly select a segment of noise.\n",
    "            else:\n",
    "                noise_start = random_state.randint(0, noise_length - speech_length, size=1)[0]\n",
    "                noise_end = noise_start + speech_length\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                print(count)\n",
    "\n",
    "            count += 1\n",
    "            csv_file.write(\"%s\\t%s\\t%d\\t%d\\n\" % (speech_file_name, noise_file_name, noise_start, noise_end))\n",
    "\n",
    "    csv_file.close()\n",
    "    print(output_csv_path)\n",
    "    print(\"Create %s mixture CSV finished!\" % data_type)\n",
    "    \n",
    "def calculate_features(args):\n",
    "    workspace_path = args.workspace_path\n",
    "    speech_directory = args.speech_directory\n",
    "    noise_directory = args.noise_directory\n",
    "    data_type = args.data_type\n",
    "    snr = args.snr\n",
    "    sample_rate = cfg.sample_rate\n",
    "    \n",
    "    # Open mixture CSV. \n",
    "    mixture_csv_path = os.path.join(workspace_path, \"mixture_csvs\", \"%s.csv\" % data_type)\n",
    "    with open(mixture_csv_path, 'rb') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        data_list = list(reader)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    count = 0\n",
    "    for i1 in range(1, len(data_list)):\n",
    "        [speech_name, noise_name, noise_start, noise_end] = data_list[i1]\n",
    "        noise_start = int(noise_start)\n",
    "        noise_end = int(noise_end)\n",
    "        \n",
    "        # Read speech audio. \n",
    "        speech_path = os.path.join(speech_directory, speech_name)\n",
    "        (speech_audio, _) = read_audio(speech_path, target_fs=sample_rate)\n",
    "        \n",
    "        # Read noise audio. \n",
    "        noise_path = os.path.join(noise_directory, noise_name)\n",
    "        (noise_audio, _) = read_audio(noise_path, target_fs=sample_rate)\n",
    "        \n",
    "        # Repeat noise to the same length as speech. \n",
    "        if len(noise_audio) < len(speech_audio):\n",
    "            repetitions = int(np.ceil(float(len(speech_audio)) / float(len(noise_audio)))\n",
    "            noise_audio_extended = np.tile(noise_audio, repetitions)\n",
    "            noise_audio = noise_audio_extended[0 : len(speech_audio)]\n",
    "        # Truncate noise to the same length as speech. \n",
    "        else:\n",
    "            noise_audio = noise_audio[noise_start : noise_end]\n",
    "        \n",
    "        # Scale speech to the given SNR. \n",
    "        scaling_factor = get_scaling_factor(speech_audio, noise_audio, snr=snr)\n",
    "        speech_audio *= scaling_factor\n",
    "        \n",
    "        # Get normalized mixture, speech, noise. \n",
    "        (mixed_audio, speech_audio, noise_audio, alpha) = additive_mixing(speech_audio, noise_audio)\n",
    "\n",
    "        # Write out mixed audio. \n",
    "        output_base_name = os.path.join(\"%s.%s\" % \n",
    "            (os.path.splitext(speech_name)[0], os.path.splitext(noise_name)[0]))\n",
    "        output_audio_path = os.path.join(workspace_path, \"mixed_audios\", \"spectrogram\", \n",
    "            data_type, \"%ddb\" % int(snr), \"%s.wav\" % output_base_name)\n",
    "        create_directory(os.path.dirname(output_audio_path))\n",
    "        write_audio_file(output_audio_path, mixed_audio, sample_rate)\n",
    "\n",
    "        # Extract spectrogram. \n",
    "        mixed_complex_spectrogram = calculate_spectrogram(mixed_audio, mode='complex')\n",
    "        speech_spectrogram = calculate_spectrogram(speech_audio, mode='magnitude')\n",
    "        noise_spectrogram = calculate_spectrogram(noise_audio, mode='magnitude')\n",
    "\n",
    "        # Write out features. \n",
    "        output_feature_path = os.path.join(workspace_path, \"features\", \"spectrogram\", \n",
    "            data_type, \"%ddb\" % int(snr), \"%s.p\" % output_base_name)\n",
    "        create_directory(os.path.dirname(output_feature_path))\n",
    "        data = [mixed_complex_spectrogram, speech_spectrogram, noise_spectrogram, alpha, output_base_name]\n",
    "        cPickle.dump(data, open(output_feature_path, 'wb'), protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        # Print. \n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "            \n",
    "        count += 1\n",
    "\n",
    "    print(\"Extracting feature time: %s\" % (time.time() - t1))\n",
    "\n",
    "def root_mean_square(y):\n",
    "    return np.sqrt(np.mean(np.abs(y) ** 2, axis=0, keepdims=False))\n",
    "\n",
    "def get_scaling_factor(source, noise, snr, method='rms'):\n",
    "    original_snr_rms_ratio = root_mean_square(source) / root_mean_square(noise)\n",
    "    target_snr_rms_ratio =  10. ** (float(snr) / 20.)    # snr = 20 * lg(rms(source) / rms(noise))\n",
    "    signal_scaling_factor = target_snr_rms_ratio / original_snr_rms_ratio\n",
    "    return signal_scaling_factor\n",
    "                              \n",
    "def mix_sources(source1, source2):\n",
    "    mixed_audio = source1 + source2\n",
    "        \n",
    "    alpha = 1. / np.max(np.abs(mixed_audio))\n",
    "    mixed_audio *= alpha\n",
    "    source1 *= alpha\n",
    "    source2 *= alpha\n",
    "    return mixed_audio, source1, source2, alpha\n",
    "    \n",
    "def calculate_spectrogram(audio, mode):\n",
    "    window_length = cfg.window_length\n",
    "    overlap = cfg.overlap\n",
    "    hamming_window = np.hamming(window_length)\n",
    "    [frequencies, time_points, spectrogram] = signal.spectral.spectrogram(\n",
    "                    audio, \n",
    "                    window=hamming_window,\n",
    "                    nperseg=window_length, \n",
    "                    noverlap=overlap, \n",
    "                    detrend=False, \n",
    "                    return_onesided=True, \n",
    "                    mode=mode) \n",
    "    spectrogram = spectrogram.T\n",
    "    if mode == 'magnitude':\n",
    "        spectrogram = spectrogram.astype(np.float32)\n",
    "    elif mode == 'complex':\n",
    "        spectrogram = spectrogram.astype(np.complex64)\n",
    "    else:\n",
    "        raise Exception(\"Incorrect mode!\")\n",
    "    return spectrogram\n",
    "            \n",
    "def prepare_features(args):\n",
    "    workspace = args.workspace\n",
    "    data_type = args.data_type\n",
    "    snr = args.snr\n",
    "    n_concat = args.n_concat\n",
    "    n_hop = args.n_hop\n",
    "    \n",
    "    x_all = []  # (n_segments, n_concat, n_freq)\n",
    "    y_all = []  # (n_segments, n_freq)\n",
    "    \n",
    "    cnt = 0\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Load all features. \n",
    "    feature_directory = os.path.join(workspace, \"features\", \"spectrogram\", data_type, \"%ddb\" % int(snr))\n",
    "    feature_names = os.listdir(feature_directory)\n",
    "    \n",
    "    for name in feature_names:\n",
    "        # Load feature. \n",
    "        feature_path = os.path.join(feature_directory, name)\n",
    "        data = cPickle.load(open(feature_path, 'rb'))\n",
    "        [mixed_complex_spectrogram, speech_spectrogram, noise_spectrogram, alpha, name] = data\n",
    "        mixed_spectrogram = np.abs(mixed_complex_spectrogram)\n",
    "\n",
    "        # Pad the start and finish of the spectrogram with border values. \n",
    "        n_padding = (n_concat - 1) / 2\n",
    "        mixed_spectrogram = pad_with_border(mixed_spectrogram, n_padding)\n",
    "        speech_spectrogram = pad_with_border(speech_spectrogram, n_padding)\n",
    "    \n",
    "        # Cut input spectrogram to 3D segments with n_concat. \n",
    "        mixed_spectrogram_3d = segment_2d_to_3d(mixed_spectrogram, aggregation_number=n_concat, hop=n_hop)\n",
    "        x_all.append(mixed_spectrogram_3d)\n",
    "        \n",
    "        # Cut target spectrogram and take the center frame of each 3D segment. \n",
    "        speech_spectrogram_3d = segment_2d_to_3d(speech_spectrogram, aggregation_number=n_concat, hop=n_hop)\n",
    "        y = speech_spectrogram_3d[:, (n_concat - 1) / 2, :]\n",
    "        y_all.append(y)\n",
    "    \n",
    "        # Print. \n",
    "        if cnt % 100 == 0:\n",
    "            print(cnt)\n",
    "            \n",
    "        # if cnt == 3: break\n",
    "        cnt += 1\n",
    "        \n",
    "    x_all = np.concatenate(x_all, axis=0)   # (n_segments, n_concat, n_freq)\n",
    "    y_all = np.concatenate(y_all, axis=0)   # (n_segments, n_freq)\n",
    "    \n",
    "    x_all = apply_logarithm(x_all).astype(np.float32)\n",
    "    y_all = apply_logarithm(y_all).astype(np.float32)\n",
    "    \n",
    "    # Write out data to .h5 file. \n",
    "    out_path = os.path.join(workspace, \"packed_features\", \"spectrogram\", data_type, \"%ddb\" % int(snr), \"data.h5\")\n",
    "    create_folder(os.path.dirname(out_path))\n",
    "    with h5py.File(out_path, 'w') as h5_file:\n",
    "        h5_file.create_dataset('x', data=x_all)\n",
    "        h5_file.create_dataset('y', data=y_all)\n",
    "    \n",
    "    print(\"Write out to %s\" % out_path)\n",
    "    print(\"Prepare features finished! %s s\" % (time.time() - t1,))\n",
    "    \n",
    "def apply_logarithm(x):\n",
    "    return np.log(x + 1e-08)\n",
    "    \n",
    "def segment_2d_to_3d(x, aggregation_number, hop):\n",
    "    # Pad to at least one block. \n",
    "    len_x, n_features = x.shape\n",
    "    if (len_x < aggregation_number):\n",
    "        x = np.concatenate((x, np.zeros((aggregation_number - len_x, n_features))))\n",
    "        \n",
    "    # Segment 2D to 3D. \n",
    "    len_x = len(x)\n",
    "    i = 0\n",
    "    x3d = []\n",
    "    while (i + aggregation_number <= len_x):\n",
    "        x3d.append(x[i : i + aggregation_number])\n",
    "        i += hop\n",
    "    return np.array(x3d)\n",
    "\n",
    "def pad_with_border(x, n_padding):\n",
    "    x_pad_list = [x[0:1]] * n_padding + [x] + [x[-1:]] * n_padding\n",
    "    return np.concatenate(x_pad_list, axis=0)\n",
    "                              \n",
    "def compute_data_scaler(args):\n",
    "    workspace_directory = args.workspace\n",
    "    data_type = args.data_type\n",
    "    snr = args.snr\n",
    "    \n",
    "    # Load data. \n",
    "    t1 = time.time()\n",
    "    hdf5_file_path = os.path.join(workspace_directory, \"packed_features\", \"spectrogram\", data_type, \"%ddb\" % int(snr), \"data.h5\")\n",
    "    with h5py.File(hdf5_file_path, 'r') as h5_file:\n",
    "        x_data = h5_file.get('x')     \n",
    "        x_data = np.array(x_data)     # (n_segments, n_concat, n_freq)\n",
    "    \n",
    "    # Compute the scaler. \n",
    "    (n_segments, n_concat, n_freq) = x_data.shape\n",
    "    x2d_data = x_data.reshape((n_segments * n_concat, n_freq))\n",
    "    data_scaler = preprocessing.StandardScaler(with_mean=True, with_std=True).fit(x2d_data)\n",
    "    print(data_scaler.mean_)\n",
    "    print(data_scaler.scale_)\n",
    "    \n",
    "    # Write out the scaler. \n",
    "    scaler_file_path = os.path.join(workspace_directory, \"packed_features\", \"spectrogram\", data_type, \"%ddb\" % int(snr), \"scaler.p\")\n",
    "    create_folder(os.path.dirname(scaler_file_path))\n",
    "    pickle.dump(data_scaler, open(scaler_file_path, 'wb'))\n",
    "    \n",
    "    print(\"Save the scaler to %s\" % scaler_file_path)\n",
    "    print(\"Compute the scaler finished! %s s\" % (time.time() - t1))\n",
    "    \n",
    "def scale_2d_data(x2d, scaler):\n",
    "    return scaler.transform(x2d)\n",
    "    \n",
    "def scale_3d_data(x3d, scaler):\n",
    "    (n_segments, n_concat, n_freq) = x3d.shape\n",
    "    x2d_data = x3d.reshape((n_segments * n_concat, n_freq))\n",
    "    x2d_data = scaler.transform(x2d_data)\n",
    "    x3d_data = x2d_data.reshape((n_segments, n_concat, n_freq))\n",
    "    return x3d_data\n",
    "    \n",
    "def inverse_scale_2d_data(x2d, scaler):\n",
    "    return x2d * scaler.scale_[None, :] + scaler.mean_[None, :]\n",
    "    \n",
    "def load_data_from_hdf5(hdf5_file_path):\n",
    "    with h5py.File(hdf5_file_path, 'r') as h5_file:\n",
    "        x_data = h5_file.get('x')\n",
    "        y_data = h5_file.get('y')\n",
    "        x_data = np.array(x_data)     # (n_segments, n_concat, n_freq)\n",
    "        y_data = np.array(y_data)     # (n_segments, n_freq)        \n",
    "    return x_data, y_data\n",
    "\n",
    "def np_mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    subparsers = parser.add_subparsers(dest='mode')\n",
    "\n",
    "    parser_create_mixture_csv = subparsers.add_parser('create_mixture_csv')\n",
    "    parser_create_mixture_csv.add_argument('--workspace', type=str, required=True)\n",
    "    parser_create_mixture_csv.add_argument('--speech_dir', type=str, required=True)\n",
    "    parser_create_mixture_csv.add_argument('--noise_dir', type=str, required=True)\n",
    "    parser_create_mixture_csv.add_argument('--data_type', type=str, required=True)\n",
    "    parser_create_mixture_csv.add_argument('--magnification', type=int, default=1)\n",
    "\n",
    "    parser_calculate_mixture_features = subparsers.add_parser('calculate_mixture_features')\n",
    "    parser_calculate_mixture_features.add_argument('--workspace', type=str, required=True)\n",
    "    parser_calculate_mixture_features.add_argument('--speech_dir', type=str, required=True)\n",
    "    parser_calculate_mixture_features.add_argument('--noise_dir', type=str, required=True)\n",
    "    parser_calculate_mixture_features.add_argument('--data_type', type=str, required=True)\n",
    "    parser_calculate_mixture_features.add_argument('--snr', type=float, required=True)\n",
    "    \n",
    "    parser_pack_features = subparsers.add_parser('pack_features')\n",
    "    parser_pack_features.add_argument('--workspace', type=str, required=True)\n",
    "    parser_pack_features.add_argument('--data_type', type=str, required=True)\n",
    "    parser_pack_features.add_argument('--snr', type=float, required=True)\n",
    "    parser_pack_features.add_argument('--n_concat', type=int, required=True)\n",
    "    parser_pack_features.add_argument('--n_hop', type=int, required=True)\n",
    "    \n",
    "    parser_compute_data_scaler = subparsers.add_parser('compute_data_scaler')\n",
    "    parser_compute_data_scaler.add_argument('--workspace', type=str, required=True)\n",
    "    parser_compute_data_scaler.add_argument('--data_type', type=str, required=True)\n",
    "    parser_compute_data_scaler.add_argument('--snr', type=float, required=True)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    if args.mode == 'create_mixture_csv':\n",
    "        create_mixture_csv(args)\n",
    "    elif args.mode == 'calculate_mixture_features':\n",
    "        calculate_mixture_features(args)\n",
    "    elif args.mode == 'pack_features':\n",
    "        pack_features(args)       \n",
    "    elif args.mode == 'compute_data_scaler':\n",
    "        compute_data_scaler(args)\n",
    "    else:\n",
    "        raise Exception(\"Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self, batch_size, data_type, max_iterations=None):\n",
    "        assert data_type in ['train', 'test']\n",
    "        self._batch_size_ = batch_size\n",
    "        self._data_type_ = data_type\n",
    "        self._max_iterations_ = max_iterations\n",
    "        \n",
    "    def generate(self, x_data, y_data):\n",
    "        x = x_data[0]\n",
    "        y = y_data[0]\n",
    "        batch_size = self._batch_size_\n",
    "        num_samples = len(x)\n",
    "        \n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        iterations = 0\n",
    "        epochs = 0\n",
    "        pointer = 0\n",
    "        while True:\n",
    "            if (self._data_type_ == 'test') and (self._max_iterations_ is not None):\n",
    "                if iterations == self._max_iterations_:\n",
    "                    break\n",
    "            iterations += 1\n",
    "            if pointer >= num_samples:\n",
    "                epochs += 1\n",
    "                if (self._data_type_) == 'test' and (epochs == 1):\n",
    "                    break\n",
    "                pointer = 0\n",
    "                np.random.shuffle(indices)                \n",
    " \n",
    "            batch_indices = indices[pointer : min(pointer + batch_size, num_samples)]\n",
    "            pointer += batch_size\n",
    "            yield x[batch_indices], y[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "import decimal\n",
    "\n",
    "def recover_wav(predicted_abs_spectrum, ground_truth_spectrum, overlap, window_function, target_wav_length=None):\n",
    "    x = real_to_complex(predicted_abs_spectrum, ground_truth_spectrum)\n",
    "    x = half_to_whole(x)\n",
    "    frames = ifft_to_wav(x)\n",
    "    (n_frames, n_window) = frames.shape\n",
    "    audio_signal = deframesig(frames=frames, siglen=0, frame_len=n_window, \n",
    "                   frame_step=n_window-overlap, winfunc=window_function)\n",
    "    if target_wav_length:\n",
    "        audio_signal = pad_or_truncate(audio_signal, target_wav_length)\n",
    "    return audio_signal\n",
    "    \n",
    "def real_to_complex(predicted_abs_spectrum, ground_truth_spectrum):\n",
    "    phase = np.angle(ground_truth_spectrum)\n",
    "    complex_spectrum = predicted_abs_spectrum * np.exp(1j * phase)\n",
    "    return complex_spectrum\n",
    "    \n",
    "def half_to_whole(x):\n",
    "    return np.concatenate((x, np.fliplr(np.conj(x[:, 1:-1]))), axis=1)\n",
    "\n",
    "def ifft_to_wav(x):\n",
    "    return np.real(np.fft.ifft(x))\n",
    "\n",
    "def pad_or_truncate(s, target_length):\n",
    "    if len(s) >= target_length:\n",
    "        s = s[0 : target_length]\n",
    "    else:\n",
    "        s = np.concatenate((s, np.zeros(target_length - len(s))))\n",
    "    return s\n",
    "\n",
    "def recover_gt_wav(x, overlap, window_function, target_wav_length=None):\n",
    "    x = half_to_whole(x)\n",
    "    frames = ifft_to_wav(x)\n",
    "    (n_frames, n_window) = frames.shape\n",
    "    audio_signal = deframesig(frames=frames, siglen=0, frame_len=n_window, \n",
    "                   frame_step=n_window-overlap, winfunc=window_function)\n",
    "    if target_wav_length:\n",
    "        audio_signal = pad_or_truncate(audio_signal, target_wav_length)\n",
    "    return audio_signal\n",
    "\n",
    "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,))):    \n",
    "    frame_len = round_half_up(frame_len)\n",
    "    frame_step = round_half_up(frame_step)\n",
    "    numframes = numpy.shape(frames)[0]\n",
    "    assert numpy.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
    " \n",
    "    indices = numpy.tile(numpy.arange(0,frame_len),(numframes,1)) + numpy.tile(numpy.arange(0,numframes*frame_step,frame_step),(frame_len,1)).T\n",
    "    indices = numpy.array(indices,dtype=numpy.int32)\n",
    "    padlen = (numframes-1)*frame_step + frame_len   \n",
    "    \n",
    "    if siglen <= 0:\n",
    "        siglen = padlen\n",
    "    \n",
    "    reconstructed_signal = numpy.zeros((padlen,))\n",
    "    window_correction = numpy.zeros((padlen,))\n",
    "    win = winfunc(frame_len)\n",
    "    \n",
    "    for i in range(0, numframes):\n",
    "        window_correction[indices[i,:]] = window_correction[indices[i,:]] + win + 1e-15 #add a little bit so it is never zero\n",
    "        reconstructed_signal[indices[i,:]] = reconstructed_signal[indices[i,:]] + frames[i,:]\n",
    "        \n",
    "    reconstructed_signal = reconstructed_signal / window_correction\n",
    "    return reconstructed_signal[0:siglen]\n",
    "    \n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7cfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import cPickle\n",
    "import h5py\n",
    "import argparse\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "sample_rate = 16000\n",
    "n_window = 512\n",
    "n_overlap = 256 \n",
    "\n",
    "def evaluate(model, generator, x, y):\n",
    "    predicted_all, y_all = [], []\n",
    "    \n",
    "    # Inference in mini batch. \n",
    "    for (batch_x, batch_y) in generator.generate(xs=[x], ys=[y]):\n",
    "        predicted = model.predict(batch_x)\n",
    "        predicted_all.append(predicted)\n",
    "        y_all.append(batch_y)\n",
    "        \n",
    "    # Concatenate mini batch prediction. \n",
    "    predicted_all = np.concatenate(predicted_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "    \n",
    "    # Compute loss. \n",
    "    loss = data_preparation.np_mean_absolute_error(y_all, predicted_all)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def train(args):\n",
    "    print(args)\n",
    "    workspace = args.workspace\n",
    "    training_snr = args.tr_snr\n",
    "    testing_snr = args.te_snr\n",
    "    learning_rate = args.lr\n",
    "    \n",
    "    # Load data. \n",
    "    t1 = time.time()\n",
    "    training_hdf5_path = os.path.join(workspace, \"packed_features\", \"spectrogram\", \"train\", \"%ddb\" % int(training_snr), \"data.h5\")\n",
    "    testing_hdf5_path = os.path.join(workspace, \"packed_features\", \"spectrogram\", \"test\", \"%ddb\" % int(testing_snr), \"data.h5\")\n",
    "    (training_x, training_y) = data_preparation.load_hdf5(training_hdf5_path)\n",
    "    (testing_x, testing_y) = data_preparation.load_hdf5(testing_hdf5_path)\n",
    "    print(training_x.shape, training_y.shape)\n",
    "    print(testing_x.shape, testing_y.shape)\n",
    "    print(\"Load data time: %s s\" % (time.time() - t1,))\n",
    "    \n",
    "    batch_size = 500\n",
    "    print(\"%d iterations / epoch\" % int(training_x.shape[0] / batch_size))\n",
    "    \n",
    "    # Scale data. \n",
    "    if True:\n",
    "        t1 = time.time()\n",
    "        scaler_path = os.path.join(workspace, \"packed_features\", \"spectrogram\", \"train\", \"%ddb\" % int(training_snr), \"scaler.p\")\n",
    "        scaler = pickle.load(open(scaler_path, 'rb'))\n",
    "        training_x = data_preparation.scale_on_3d(training_x, scaler)\n",
    "        training_y = data_preparation.scale_on_2d(training_y, scaler)\n",
    "        testing_x = data_preparation.scale_on_3d(testing_x, scaler)\n",
    "        testing_y = data_preparation.scale_on_2d(testing_y, scaler)\n",
    "        print(\"Scale data time: %s s\" % (time.time() - t1,))\n",
    "        \n",
    "    # Debug plot. \n",
    "    if False:\n",
    "        plt.matshow(training_x[0 : 1000, 0, :].T, origin='lower', aspect='auto', cmap='jet')\n",
    "        plt.show()\n",
    "        pause\n",
    "        \n",
    "    # Build model\n",
    "    (_, n_concat, n_freq) = training_x.shape\n",
    "    n_hidden = 2048\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(n_concat, n_freq))\n",
    "    model.add(Dense(n_hidden, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_hidden, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_hidden, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_freq, activation='linear'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=Adam(lr=learning_rate))\n",
    "    train_data_generator = DataGenerator(batch_size=batch_size, type='train')\n",
    "    eval_test_data_generator = DataGenerator(batch_size=batch_size, type='test', te_max_iter=100)\n",
    "    eval_train_data_generator = DataGenerator(batch_size=batch_size, type='test', te_max_iter=100)\n",
    "\n",
    "    # Directories for saving models and training stats\n",
    "    model_directory = os.path.join(workspace, \"models\", \"%ddb\" % int(tr_snr))\n",
    "    pp_data.create_folder(model_directory)\n",
    "\n",
    "    stats_directory = os.path.join(workspace, \"training_stats\", \"%ddb\" % int(tr_snr))\n",
    "    pp_data.create_folder(stats_directory)\n",
    "\n",
    "    # Print loss before training.\n",
    "    iteration = 0\n",
    "    training_loss = eval(model, eval_train_data_generator, tr_x, tr_y)\n",
    "    test_loss = eval(model, eval_test_data_generator, te_x, te_y)\n",
    "    print(\"Iteration: %d, training_loss: %f, test_loss: %f\" % (iteration, training_loss, test_loss)\n",
    "\n",
    "    # Save out training stats.\n",
    "    stat_dict = {'iteration': iteration,\n",
    "                 'training_loss': training_loss,\n",
    "                 'test_loss': test_loss}\n",
    "    stat_path = os.path.join(stats_directory, \"%diters.p\" % iteration)\n",
    "    cPickle.dump(stat_dict, open(stat_path, 'wb'), protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Train.\n",
    "    t1 = time.time()\n",
    "    for (batch_x, batch_y) in train_data_generator.generate(xs=[tr_x], ys=[tr_y]):\n",
    "        loss = model.train_on_batch(batch_x, batch_y)\n",
    "        iteration += 1\n",
    "\n",
    "        # Validate and save training stats.\n",
    "        if iteration % 1000 == 0:\n",
    "            training_loss = eval(model, eval_train_data_generator, tr_x, tr_y)\n",
    "            test_loss = eval(model, eval_test_data_generator, te_x, te_y)\n",
    "            print(\"Iteration: %d, training_loss: %f, test_loss: %f\" % (iteration, training_loss, test_loss)\n",
    "\n",
    "            # Save out training stats.\n",
    "            stat_dict = {'iteration': iteration,\n",
    "                         'training_loss': training_loss,\n",
    "                         'test_loss': test_loss}\n",
    "            stat_path = os.path.join(stats_directory, \"%diters.p\" % iteration)\n",
    "            cPickle.dump(stat_dict, open(stat_path, 'wb'), protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # Save model.\n",
    "        if iteration % 5000 == 0:\n",
    "            model_path = os.path.join(model_directory, \"md_%diters.h5\" % iteration)\n",
    "            model.save(model_path)\n",
    "            print(\"Saved model to %s\" % model_path)\n",
    "\n",
    "        if iteration == 10001:\n",
    "            break\n",
    "\n",
    "    print(\"Training time: %s s\" % (time.time() - t1))\n",
    "\n",
    "def inference(args):\n",
    "    print(args)\n",
    "    workspace = args.workspace\n",
    "    tr_snr = args.tr_snr\n",
    "    te_snr = args.te_snr\n",
    "    n_concat = args.n_concat\n",
    "    iteration = args.iteration\n",
    "    \n",
    "    n_window = cfg.n_window\n",
    "    n_overlap = cfg.n_overlap\n",
    "    fs = cfg.sample_rate\n",
    "    scale = True\n",
    "    \n",
    "    # Load model. \n",
    "    model_path = os.path.join(workspace, \"models\", \"%ddb\" % int(tr_snr), \"md_%diters.h5\" % iteration)\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load scaler. \n",
    "    scaler_path = os.path.join(workspace, \"packed_features\", \"spectrogram\", \"train\", \"%ddb\" % int(tr_snr), \"scaler.p\")\n",
    "    scaler = pickle.load(open(scaler_path, 'rb'))\n",
    "    \n",
    "    # Load test data. \n",
    "    feat_dir = os.path.join(workspace, \"features\", \"spectrogram\", \"test\", \"%ddb\" % int(te_snr))\n",
    "    file_names = os.listdir(feat_dir)\n",
    "\n",
    "    for (cnt, file_name) in enumerate(file_names):\n",
    "        # Load feature. \n",
    "        feat_path = os.path.join(feat_dir, file_name)\n",
    "        data = cPickle.load(open(feat_path, 'rb'))\n",
    "        [mixed_complex_x, speech_x, noise_x, alpha, file_name] = data\n",
    "        mixed_x = np.abs(mixed_complex_x)\n",
    "        \n",
    "        # Process data. \n",
    "        n_pad = (n_concat - 1) // 2\n",
    "        mixed_x = pp_data.pad_with_border(mixed_x, n_pad)\n",
    "        mixed_x = pp_data.log_sp(mixed_x)\n",
    "        speech_x = pp_data.log_sp(speech_x)\n",
    "        \n",
    "        # Scale data. \n",
    "        if scale:\n",
    "            mixed_x = pp_data.scale_on_2d(mixed_x, scaler)\n",
    "            speech_x = pp_data.scale_on_2d(speech_x, scaler)\n",
    "        \n",
    "        # Cut input spectrogram to 3D segments with n_concat. \n",
    "        mixed_x_3d = pp_data.mat_2d_to_3d(mixed_x, agg_num=n_concat, hop=1)\n",
    "        \n",
    "        # Predict. \n",
    "        pred = model.predict(mixed_x_3d)\n",
    "        print(cnt, file_name)\n",
    "        \n",
    "        # Inverse scale. \n",
    "        if scale:\n",
    "            mixed_x = pp_data.inverse_scale_on_2d(mixed_x, scaler)\n",
    "            speech_x = pp_data.inverse_scale_on_2d(speech_x, scaler)\n",
    "            pred = pp_data.inverse_scale_on_2d(pred, scaler)\n",
    "        \n",
    "        # Debug plot. \n",
    "        if args.visualize:\n",
    "            fig, axs = plt.subplots(3, 1, sharex=False)\n",
    "            axs[0].matshow(mixed_x.T, origin='lower', aspect='auto', cmap='jet')\n",
    "            axs[1].matshow(speech_x.T, origin='lower', aspect='auto', cmap='jet')\n",
    "            axs[2].matshow(pred.T, origin='lower', aspect='auto', cmap='jet')\n",
    "            axs[0].set_title(\"%ddb mixture log spectrogram\" % int(te_snr))\n",
    "            axs[1].set_title(\"Clean speech log spectrogram\")\n",
    "            axs[2].set_title(\"Enhanced speech log spectrogram\")\n",
    "            for j1 in range(3):\n",
    "                axs[j1].xaxis.tick_bottom()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Recover enhanced wav. \n",
    "        pred_sp = np.exp(pred)\n",
    "        s = recover_wav(pred_sp, mixed_complex_x, n_overlap, np.hamming)\n",
    "        s *= np.sqrt((np.hamming(n_window)**2).sum())   # Scaler to compensate the amplitude \n",
    "                                                        # change after spectrogram and IFFT. \n",
    "        \n",
    "        # Write out enhanced wav. \n",
    "        out_path = os.path.join(workspace, \"enh_wavs\", \"test\", \"%ddb\" % int(te_snr), \"%s.enh.wav\" % file_name)\n",
    "        pp_data.create_folder(os.path.dirname(out_path))\n",
    "        pp_data.write_audio(out_path, s, fs) \n",
    "                  \n",
    "if __name__ == '__main__':\n",
    "    argument_parser = argparse.ArgumentParser()\n",
    "    subparsers = argument_parser.add_subparsers(dest='mode')\n",
    "\n",
    "    train_parser = subparsers.add_parser('train')\n",
    "    train_parser.add_argument('--workspace', type=str, required=True)\n",
    "    train_parser.add_argument('--training_snr', type=float, required=True)\n",
    "    train_parser.add_argument('--testing_snr', type=float, required=True)\n",
    "    train_parser.add_argument('--learning_rate', type=float, required=True)\n",
    "    \n",
    "    inference_parser = subparsers.add_parser('inference')\n",
    "    inference_parser.add_argument('--workspace', type=str, required=True)\n",
    "    inference_parser.add_argument('--training_snr', type=float, required=True)\n",
    "    inference_parser.add_argument('--testing_snr', type=float, required=True)\n",
    "    inference_parser.add_argument('--n_concat', type=int, required=True)\n",
    "    inference_parser.add_argument('--iteration', type=int, required=True)\n",
    "    inference_parser.add_argument('--visualize', action='store_true', default=False)\n",
    "    \n",
    "    calculate_pesq_parser = subparsers.add_parser('calculate_pesq')\n",
    "    calculate_pesq_parser.add_argument('--workspace', type=str, required=True)\n",
    "    calculate_pesq_parser.add_argument('--speech_dir', type=str, required=True)\n",
    "    calculate_pesq_parser.add_argument('--testing_snr', type=float, required=True)\n",
    "    \n",
    "    arguments = argument_parser.parse_args()\n",
    "    \n",
    "    if arguments.mode == 'train':\n",
    "        train(arguments)\n",
    "    elif arguments.mode == 'inference':\n",
    "        inference(arguments)\n",
    "    elif arguments.mode == 'calculate_pesq':\n",
    "        calculate_pesq(arguments)\n",
    "    else:\n",
    "        raise Exception(\"Error!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
